{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# PyRevealed: Real Data Analysis\n",
    "\n",
    "This notebook tests the package on real experimental data from the Prest project.\n",
    "\n",
    "**Data Source**: [Prest budgetary dataset](https://github.com/prestsoftware/prest) - Laboratory experiments with real subjects making choices under budget constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyrevealed import (\n",
    "    BehaviorLog,\n",
    "    validate_consistency,\n",
    "    compute_integrity_score,\n",
    "    compute_confusion_metric,\n",
    "    BehavioralAuditor,\n",
    ")\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-header",
   "metadata": {},
   "source": [
    "## Load Real Data from Prest\n",
    "\n",
    "The Prest project provides budgetary choice data with Price1-6 and Demand1-6 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load budgetary dataset from Prest GitHub\n",
    "url = \"https://raw.githubusercontent.com/prestsoftware/prest/master/docs/src/_static/examples/budgetary.csv\"\n",
    "\n",
    "try:\n",
    "    budgetary = pd.read_csv(url)\n",
    "    print(f\"Loaded dataset: {budgetary.shape}\")\n",
    "    print(f\"Columns: {list(budgetary.columns)}\")\n",
    "    print(f\"\\nSubjects: {budgetary['Subject'].unique()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load data: {e}\")\n",
    "    print(\"\\nCreating synthetic fallback data...\")\n",
    "    # Fallback synthetic data\n",
    "    budgetary = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preview-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "if budgetary is not None:\n",
    "    print(\"Sample rows:\")\n",
    "    display(budgetary.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyze-header",
   "metadata": {},
   "source": [
    "## Analyze Each Subject\n",
    "\n",
    "We'll analyze each subject's behavioral consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-subjects",
   "metadata": {},
   "outputs": [],
   "source": [
    "if budgetary is not None:\n",
    "    price_cols = [f\"Price{i}\" for i in range(1, 7)]\n",
    "    demand_cols = [f\"Demand{i}\" for i in range(1, 7)]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for subject in budgetary['Subject'].unique():\n",
    "        subject_data = budgetary[budgetary['Subject'] == subject]\n",
    "        prices = subject_data[price_cols].values\n",
    "        quantities = subject_data[demand_cols].values\n",
    "        \n",
    "        # Filter out zero-price columns (some subjects have fewer goods)\n",
    "        valid_cols = (prices > 0).any(axis=0)\n",
    "        prices = prices[:, valid_cols]\n",
    "        quantities = quantities[:, valid_cols]\n",
    "        \n",
    "        # Create BehaviorLog using tech-friendly API\n",
    "        log = BehaviorLog(\n",
    "            cost_vectors=prices, \n",
    "            action_vectors=quantities,\n",
    "            user_id=str(subject)\n",
    "        )\n",
    "        \n",
    "        # Run analyses\n",
    "        garp_result = validate_consistency(log)\n",
    "        integrity_result = compute_integrity_score(log)\n",
    "        confusion_result = compute_confusion_metric(log)\n",
    "        \n",
    "        results.append({\n",
    "            'Subject': subject,\n",
    "            'Observations': log.num_records,\n",
    "            'Goods': log.num_features,\n",
    "            'GARP_Consistent': garp_result.is_consistent,\n",
    "            'Violations': len(garp_result.violations),\n",
    "            'Integrity': integrity_result.efficiency_index,\n",
    "            'Confusion': confusion_result.mpi_value,\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"Analysis Results:\")\n",
    "    display(results_df)\n",
    "else:\n",
    "    print(\"No data available - using synthetic fallback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-stats-header",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "if budgetary is not None and len(results) > 0:\n",
    "    print(f\"Total subjects: {len(results_df)}\")\n",
    "    print(f\"GARP consistent: {results_df['GARP_Consistent'].sum()} ({100*results_df['GARP_Consistent'].mean():.1f}%)\")\n",
    "    print(f\"\\nIntegrity Score (AEI):\")\n",
    "    print(f\"  Mean: {results_df['Integrity'].mean():.3f}\")\n",
    "    print(f\"  Min:  {results_df['Integrity'].min():.3f}\")\n",
    "    print(f\"  Max:  {results_df['Integrity'].max():.3f}\")\n",
    "    print(f\"\\nConfusion Score (MPI):\")\n",
    "    print(f\"  Mean: {results_df['Confusion'].mean():.3f}\")\n",
    "    print(f\"  Min:  {results_df['Confusion'].min():.3f}\")\n",
    "    print(f\"  Max:  {results_df['Confusion'].max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auditor-header",
   "metadata": {},
   "source": [
    "## Using BehavioralAuditor for Batch Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auditor-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "if budgetary is not None:\n",
    "    # Pick one subject for detailed audit\n",
    "    subject = budgetary['Subject'].unique()[0]\n",
    "    subject_data = budgetary[budgetary['Subject'] == subject]\n",
    "    prices = subject_data[price_cols].values\n",
    "    quantities = subject_data[demand_cols].values\n",
    "    \n",
    "    valid_cols = (prices > 0).any(axis=0)\n",
    "    prices = prices[:, valid_cols]\n",
    "    quantities = quantities[:, valid_cols]\n",
    "    \n",
    "    log = BehaviorLog(cost_vectors=prices, action_vectors=quantities)\n",
    "    \n",
    "    # Use high-level auditor\n",
    "    auditor = BehavioralAuditor()\n",
    "    report = auditor.full_audit(log)\n",
    "    \n",
    "    print(f\"Subject {subject} Full Audit:\")\n",
    "    print(f\"  Consistent: {report.is_consistent}\")\n",
    "    print(f\"  Integrity:  {report.integrity_score:.3f}\")\n",
    "    print(f\"  Confusion:  {report.confusion_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallback-header",
   "metadata": {},
   "source": [
    "## Fallback: Synthetic Real-World Style Data\n",
    "\n",
    "If the remote data isn't available, create synthetic data mimicking real patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallback-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "if budgetary is None:\n",
    "    print(\"Creating synthetic grocery shopping data...\")\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Simulate 10 weeks of grocery shopping with 5 categories\n",
    "    # Categories: Produce, Dairy, Meat, Bakery, Snacks\n",
    "    n_weeks = 10\n",
    "    n_categories = 5\n",
    "    \n",
    "    # Base prices with some variation\n",
    "    base_prices = np.array([3.0, 4.0, 8.0, 2.5, 3.5])\n",
    "    prices = base_prices * (1 + 0.2 * np.random.randn(n_weeks, n_categories))\n",
    "    prices = np.maximum(prices, 0.5)  # Ensure positive\n",
    "    \n",
    "    # Quantities inversely related to prices (rational behavior)\n",
    "    budget = 50.0\n",
    "    quantities = budget / prices + 0.5 * np.random.randn(n_weeks, n_categories)\n",
    "    quantities = np.maximum(quantities, 0)  # Ensure non-negative\n",
    "    \n",
    "    log = BehaviorLog(\n",
    "        cost_vectors=prices,\n",
    "        action_vectors=quantities,\n",
    "        user_id=\"synthetic_shopper\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Created log with {log.num_records} observations, {log.num_features} features\")\n",
    "    \n",
    "    result = validate_consistency(log)\n",
    "    print(f\"\\nGARP consistent: {result.is_consistent}\")\n",
    "    \n",
    "    integrity = compute_integrity_score(log)\n",
    "    print(f\"Integrity score: {integrity.efficiency_index:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": "## Summary\n\n### Issues Found\n\n1. **SSL Certificate Error**: On some macOS Python installations, loading remote data fails with \n   `CERTIFICATE_VERIFY_FAILED`. This is a system-level Python issue, not a PyRevealed bug.\n   - Fix: Run `/Applications/Python X.X/Install Certificates.command` or use `certifi`\n   \n2. **No explicit batch processing API**: When analyzing many subjects, users must loop manually.\n   A batch API like `auditor.audit_batch([log1, log2, ...])` would be convenient.\n\n### What Worked\n\n- Clean fallback to synthetic data when remote loading fails\n- BehaviorLog works seamlessly with pandas-extracted numpy arrays\n- Batch analysis loop pattern works correctly\n- All metrics compute correctly for each subject\n- Results can be collected into DataFrames for comparison"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}