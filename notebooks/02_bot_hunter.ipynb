{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bot Hunter: Detecting Automated Behavior via Consistency Analysis\n",
    "\n",
    "This notebook demonstrates how to use revealed preference theory to detect bots and automated scripts.\n",
    "\n",
    "**Key Insight**: Humans typically make consistent choices (high AEI). Bots that click randomly or follow hard-coded rules often fail consistency tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyrevealed import ConsumerSession, compute_aei, check_garp\n",
    "from pyrevealed.viz import plot_aei_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simulating Human vs Bot Behavior\n",
    "\n",
    "Let's simulate:\n",
    "- **Human users**: Make choices that roughly maximize utility\n",
    "- **Bot users**: Make random or scripted choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rational_user(n_observations=20, n_goods=3, noise=0.1):\n",
    "    \"\"\"\n",
    "    Generate data for a roughly rational user.\n",
    "    They prefer cheaper goods with some noise.\n",
    "    \"\"\"\n",
    "    prices = np.random.uniform(0.5, 2.0, (n_observations, n_goods))\n",
    "    \n",
    "    # Rational behavior: spend more on cheaper goods\n",
    "    budget = 10.0\n",
    "    quantities = np.zeros((n_observations, n_goods))\n",
    "    \n",
    "    for t in range(n_observations):\n",
    "        # Prefer goods with lower prices (inverse relationship)\n",
    "        preferences = 1.0 / prices[t] + np.random.normal(0, noise, n_goods)\n",
    "        preferences = np.maximum(preferences, 0.1)\n",
    "        preferences = preferences / preferences.sum()\n",
    "        \n",
    "        # Allocate budget according to preferences\n",
    "        spending = preferences * budget\n",
    "        quantities[t] = spending / prices[t]\n",
    "    \n",
    "    return ConsumerSession(prices=prices, quantities=quantities)\n",
    "\n",
    "\n",
    "def generate_random_bot(n_observations=20, n_goods=3):\n",
    "    \"\"\"\n",
    "    Generate data for a bot that clicks randomly.\n",
    "    No regard for prices - purely random behavior.\n",
    "    \"\"\"\n",
    "    prices = np.random.uniform(0.5, 2.0, (n_observations, n_goods))\n",
    "    quantities = np.random.uniform(0, 5, (n_observations, n_goods))\n",
    "    \n",
    "    return ConsumerSession(prices=prices, quantities=quantities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample users\n",
    "np.random.seed(42)\n",
    "\n",
    "human_user = generate_rational_user(n_observations=30)\n",
    "bot_user = generate_random_bot(n_observations=30)\n",
    "\n",
    "print(\"Human user sample:\")\n",
    "print(f\"  Prices shape: {human_user.prices.shape}\")\n",
    "print(f\"  Quantities shape: {human_user.quantities.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyzing Consistency Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute AEI for both\n",
    "human_aei = compute_aei(human_user)\n",
    "bot_aei = compute_aei(bot_user)\n",
    "\n",
    "print(\"Consistency Analysis:\")\n",
    "print(f\"  Human AEI: {human_aei.efficiency_index:.4f}\")\n",
    "print(f\"  Bot AEI:   {bot_aei.efficiency_index:.4f}\")\n",
    "print()\n",
    "print(f\"  Human is perfectly consistent: {human_aei.is_perfectly_consistent}\")\n",
    "print(f\"  Bot is perfectly consistent:   {bot_aei.is_perfectly_consistent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Population Analysis\n",
    "\n",
    "Let's simulate a population with mixed humans and bots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate population\n",
    "n_humans = 80\n",
    "n_bots = 20\n",
    "\n",
    "human_scores = []\n",
    "bot_scores = []\n",
    "\n",
    "print(\"Generating population...\")\n",
    "for i in range(n_humans):\n",
    "    user = generate_rational_user(n_observations=25, noise=0.2)\n",
    "    score = compute_aei(user).efficiency_index\n",
    "    human_scores.append(score)\n",
    "\n",
    "for i in range(n_bots):\n",
    "    user = generate_random_bot(n_observations=25)\n",
    "    score = compute_aei(user).efficiency_index\n",
    "    bot_scores.append(score)\n",
    "\n",
    "print(f\"\\nHuman scores - Mean: {np.mean(human_scores):.3f}, Std: {np.std(human_scores):.3f}\")\n",
    "print(f\"Bot scores   - Mean: {np.mean(bot_scores):.3f}, Std: {np.std(bot_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(human_scores, bins=20, alpha=0.7, label='Humans', color='blue')\n",
    "axes[0].hist(bot_scores, bins=20, alpha=0.7, label='Bots', color='red')\n",
    "axes[0].axvline(0.85, color='green', linestyle='--', label='Detection Threshold')\n",
    "axes[0].set_xlabel('AEI Score')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('AEI Distribution: Humans vs Bots')\n",
    "axes[0].legend()\n",
    "\n",
    "# Combined distribution\n",
    "all_scores = human_scores + bot_scores\n",
    "plot_aei_distribution(all_scores, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bot Detection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_bot(session, threshold=0.85):\n",
    "    \"\"\"\n",
    "    Simple bot detection based on AEI threshold.\n",
    "    \n",
    "    Returns:\n",
    "        is_bot: Boolean indicating if likely a bot\n",
    "        confidence: How confident we are (distance from threshold)\n",
    "        score: The AEI score\n",
    "    \"\"\"\n",
    "    aei_result = compute_aei(session)\n",
    "    score = aei_result.efficiency_index\n",
    "    \n",
    "    is_bot = score < threshold\n",
    "    confidence = abs(score - threshold)\n",
    "    \n",
    "    return {\n",
    "        'is_bot': is_bot,\n",
    "        'confidence': confidence,\n",
    "        'score': score,\n",
    "        'is_perfect': aei_result.is_perfectly_consistent\n",
    "    }\n",
    "\n",
    "# Test on our examples\n",
    "human_result = detect_bot(human_user)\n",
    "bot_result = detect_bot(bot_user)\n",
    "\n",
    "print(\"Detection Results:\")\n",
    "print(f\"\\nHuman user: {human_result}\")\n",
    "print(f\"Bot user:   {bot_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detection Accuracy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate detection metrics\n",
    "threshold = 0.85\n",
    "\n",
    "# True positives: bots correctly identified\n",
    "true_positives = sum(1 for s in bot_scores if s < threshold)\n",
    "# False negatives: bots missed\n",
    "false_negatives = sum(1 for s in bot_scores if s >= threshold)\n",
    "# True negatives: humans correctly identified\n",
    "true_negatives = sum(1 for s in human_scores if s >= threshold)\n",
    "# False positives: humans flagged as bots\n",
    "false_positives = sum(1 for s in human_scores if s < threshold)\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"Detection Metrics (threshold={threshold}):\")\n",
    "print(f\"  Precision: {precision:.2%}\")\n",
    "print(f\"  Recall:    {recall:.2%}\")\n",
    "print(f\"  F1 Score:  {f1:.2%}\")\n",
    "print()\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(f\"  True Positives:  {true_positives}\")\n",
    "print(f\"  False Positives: {false_positives}\")\n",
    "print(f\"  True Negatives:  {true_negatives}\")\n",
    "print(f\"  False Negatives: {false_negatives}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Random bots have low AEI scores** because their choices don't follow any consistent preference pattern\n",
    "\n",
    "2. **Humans have high AEI scores** even with noise, because they roughly maximize utility\n",
    "\n",
    "3. **Threshold tuning** depends on your tolerance for false positives vs false negatives\n",
    "\n",
    "4. **This complements ML approaches** - use AEI as a feature in your fraud detection pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
