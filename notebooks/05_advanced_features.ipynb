{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T20:28:51.364991Z",
     "iopub.status.busy": "2026-01-09T20:28:51.364790Z",
     "iopub.status.idle": "2026-01-09T20:28:53.095119Z",
     "shell.execute_reply": "2026-01-09T20:28:53.094451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Install pyrevealed from PyPI (as John would do)\n",
    "!pip install pyrevealed -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5: Advanced Features\n",
    "\n",
    "This tutorial covers advanced capabilities:\n",
    "- Separability testing (are feature groups independent?)\n",
    "- Auto-discovery of independent groups\n",
    "- Cross-impact/cannibalization metrics\n",
    "- Data loading from pandas DataFrames\n",
    "- Temporal window analysis\n",
    "- Alternative consistency metrics (Houtman-Maks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T20:28:53.096666Z",
     "iopub.status.busy": "2026-01-09T20:28:53.096555Z",
     "iopub.status.idle": "2026-01-09T20:29:03.108029Z",
     "shell.execute_reply": "2026-01-09T20:29:03.106027Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyrevealed import (\n",
    "    BehaviorLog,\n",
    "    test_feature_independence,\n",
    "    discover_independent_groups,\n",
    "    compute_cross_impact,\n",
    "    compute_minimal_outlier_fraction,\n",
    "    validate_consistency,\n",
    "    compute_integrity_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Test Feature Independence (Separability)\n",
    "\n",
    "Simulate a superapp user with 4 products:\n",
    "- Group A: Rides (products 0, 1)\n",
    "- Group B: Food delivery (products 2, 3)\n",
    "\n",
    "If separable: user's spending on Rides doesn't affect Food choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T20:29:03.117309Z",
     "iopub.status.busy": "2026-01-09T20:29:03.117164Z",
     "iopub.status.idle": "2026-01-09T20:29:04.246496Z",
     "shell.execute_reply": "2026-01-09T20:29:04.245944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: superapp_user\n",
      "Is separable: True\n",
      "Cross-effect strength: 0.077\n",
      "  (0 = independent, 1 = strongly coupled)\n",
      "Within-group A (Rides) consistency: 1.000\n",
      "Within-group B (Food) consistency: 1.000\n",
      "Recommendation: price_independently\n",
      "Computation time: 1119.58 ms\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "T = 20  # 20 observations\n",
    "\n",
    "# Prices vary independently for each group\n",
    "prices_rides = np.abs(np.random.randn(T, 2)) + 1.0\n",
    "prices_food = np.abs(np.random.randn(T, 2)) + 1.5\n",
    "prices = np.hstack([prices_rides, prices_food])\n",
    "\n",
    "# Quantities respond only to own-group prices (separable behavior)\n",
    "# When ride prices go up, ride quantities go down, but food unchanged\n",
    "qty_rides = 5.0 / prices_rides\n",
    "qty_food = 4.0 / prices_food\n",
    "quantities = np.hstack([qty_rides, qty_food])\n",
    "\n",
    "log = BehaviorLog(\n",
    "    cost_vectors=prices,\n",
    "    action_vectors=quantities,\n",
    "    user_id=\"superapp_user\"\n",
    ")\n",
    "\n",
    "result = test_feature_independence(\n",
    "    log,\n",
    "    group_a=[0, 1],  # Rides\n",
    "    group_b=[2, 3],  # Food\n",
    ")\n",
    "\n",
    "print(f\"User: {log.user_id}\")\n",
    "print(f\"Is separable: {result.is_separable}\")\n",
    "print(f\"Cross-effect strength: {result.cross_effect_strength:.3f}\")\n",
    "print(f\"  (0 = independent, 1 = strongly coupled)\")\n",
    "print(f\"Within-group A (Rides) consistency: {result.within_group_a_consistency:.3f}\")\n",
    "print(f\"Within-group B (Food) consistency: {result.within_group_b_consistency:.3f}\")\n",
    "print(f\"Recommendation: {result.recommendation}\")\n",
    "print(f\"Computation time: {result.computation_time_ms:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Non-Separable Groups (Substitutes)\n",
    "\n",
    "User treats Rides and Food as substitutes. When food prices go up, they take more rides instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T20:29:04.248272Z",
     "iopub.status.busy": "2026-01-09T20:29:04.248180Z",
     "iopub.status.idle": "2026-01-09T20:29:04.252520Z",
     "shell.execute_reply": "2026-01-09T20:29:04.250985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: substitute_user\n",
      "Is separable: False\n",
      "Cross-effect strength: 0.744\n",
      "Recommendation: unified_strategy\n"
     ]
    }
   ],
   "source": [
    "qty_rides_sub = 5.0 / prices_rides + 0.5 * prices_food.mean(axis=1, keepdims=True)\n",
    "qty_food_sub = 4.0 / prices_food - 0.3 * prices_rides.mean(axis=1, keepdims=True)\n",
    "qty_food_sub = np.maximum(qty_food_sub, 0.1)  # Ensure positive\n",
    "quantities_sub = np.hstack([qty_rides_sub, qty_food_sub])\n",
    "\n",
    "log_sub = BehaviorLog(\n",
    "    cost_vectors=prices,\n",
    "    action_vectors=quantities_sub,\n",
    "    user_id=\"substitute_user\"\n",
    ")\n",
    "\n",
    "result_sub = test_feature_independence(log_sub, group_a=[0, 1], group_b=[2, 3])\n",
    "\n",
    "print(f\"User: {log_sub.user_id}\")\n",
    "print(f\"Is separable: {result_sub.is_separable}\")\n",
    "print(f\"Cross-effect strength: {result_sub.cross_effect_strength:.3f}\")\n",
    "print(f\"Recommendation: {result_sub.recommendation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Auto-Discover Independent Groups\n",
    "\n",
    "Create data with 6 goods that naturally cluster into 2 groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T20:29:04.256300Z",
     "iopub.status.busy": "2026-01-09T20:29:04.255931Z",
     "iopub.status.idle": "2026-01-09T20:29:04.261531Z",
     "shell.execute_reply": "2026-01-09T20:29:04.260853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovered 2 independent groups:\n",
      "  Group 1: goods [0, 1, 2]\n",
      "  Group 2: goods [3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "# Goods 0-2 are consumed together, Goods 3-5 are consumed together\n",
    "prices_6 = np.abs(np.random.randn(15, 6)) + 1.0\n",
    "quantities_6 = np.zeros((15, 6))\n",
    "\n",
    "for t in range(15):\n",
    "    if t % 2 == 0:\n",
    "        # Even observations: consume group 1\n",
    "        quantities_6[t, 0:3] = [3.0, 2.0, 1.0]\n",
    "    else:\n",
    "        # Odd observations: consume group 2\n",
    "        quantities_6[t, 3:6] = [2.0, 3.0, 2.0]\n",
    "\n",
    "log_6 = BehaviorLog(cost_vectors=prices_6, action_vectors=quantities_6)\n",
    "\n",
    "groups = discover_independent_groups(log_6, max_groups=2)\n",
    "\n",
    "print(f\"Discovered {len(groups)} independent groups:\")\n",
    "for i, group in enumerate(groups):\n",
    "    print(f\"  Group {i+1}: goods {group}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Compute Cross-Impact (Cannibalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T20:29:04.262959Z",
     "iopub.status.busy": "2026-01-09T20:29:04.262854Z",
     "iopub.status.idle": "2026-01-09T20:29:04.266139Z",
     "shell.execute_reply": "2026-01-09T20:29:04.265287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-impact metrics:\n",
      "  A->B (Rides cannibalizing Food): 0.600\n",
      "  B->A (Food cannibalizing Rides): 0.000\n",
      "  Symmetric cannibalization: 1.000\n",
      "  Net direction: 0.600\n",
      "    (positive = A cannibalizes B more)\n"
     ]
    }
   ],
   "source": [
    "impact = compute_cross_impact(log_sub, group_a=[0, 1], group_b=[2, 3])\n",
    "\n",
    "print(\"Cross-impact metrics:\")\n",
    "print(f\"  A->B (Rides cannibalizing Food): {impact['a_to_b']:.3f}\")\n",
    "print(f\"  B->A (Food cannibalizing Rides): {impact['b_to_a']:.3f}\")\n",
    "print(f\"  Symmetric cannibalization: {impact['symmetric']:.3f}\")\n",
    "print(f\"  Net direction: {impact['net_direction']:.3f}\")\n",
    "print(f\"    (positive = A cannibalizes B more)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Load Data from Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T20:29:04.268282Z",
     "iopub.status.busy": "2026-01-09T20:29:04.268194Z",
     "iopub.status.idle": "2026-01-09T20:29:04.273825Z",
     "shell.execute_reply": "2026-01-09T20:29:04.273008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created from wide-format DataFrame:\n",
      "  Records: 3\n",
      "  Features: 2\n",
      "  Consistent: True\n"
     ]
    }
   ],
   "source": [
    "# Wide format DataFrame\n",
    "df_wide = pd.DataFrame({\n",
    "    'price_A': [1.0, 2.0, 1.5],\n",
    "    'price_B': [2.0, 1.0, 1.5],\n",
    "    'qty_A': [3.0, 1.0, 2.0],\n",
    "    'qty_B': [1.0, 3.0, 2.0],\n",
    "})\n",
    "\n",
    "log_wide = BehaviorLog.from_dataframe(\n",
    "    df_wide,\n",
    "    cost_cols=['price_A', 'price_B'],\n",
    "    action_cols=['qty_A', 'qty_B'],\n",
    "    user_id='df_user'\n",
    ")\n",
    "\n",
    "print(\"Created from wide-format DataFrame:\")\n",
    "print(f\"  Records: {log_wide.num_records}\")\n",
    "print(f\"  Features: {log_wide.num_features}\")\n",
    "print(f\"  Consistent: {validate_consistency(log_wide).is_consistent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T20:29:04.275985Z",
     "iopub.status.busy": "2026-01-09T20:29:04.275722Z",
     "iopub.status.idle": "2026-01-09T20:29:04.286333Z",
     "shell.execute_reply": "2026-01-09T20:29:04.285919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long-format DataFrame:\n",
      "   time item_id  price  quantity\n",
      "0     0       A    1.0       3.0\n",
      "1     0       B    2.0       1.0\n",
      "2     1       A    2.0       1.0\n",
      "3     1       B    1.0       3.0\n",
      "4     2       A    1.5       2.0\n",
      "5     2       B    1.5       2.0\n",
      "\n",
      "Created from long-format DataFrame:\n",
      "  Records: 3\n",
      "  Features: 2\n"
     ]
    }
   ],
   "source": [
    "# Long format DataFrame (SQL-style transactions)\n",
    "df_long = pd.DataFrame({\n",
    "    'time': [0, 0, 1, 1, 2, 2],\n",
    "    'item_id': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
    "    'price': [1.0, 2.0, 2.0, 1.0, 1.5, 1.5],\n",
    "    'quantity': [3.0, 1.0, 1.0, 3.0, 2.0, 2.0],\n",
    "})\n",
    "\n",
    "print(\"Long-format DataFrame:\")\n",
    "print(df_long)\n",
    "\n",
    "log_long = BehaviorLog.from_long_format(\n",
    "    df_long,\n",
    "    time_col='time',\n",
    "    item_col='item_id',\n",
    "    cost_col='price',\n",
    "    action_col='quantity'\n",
    ")\n",
    "\n",
    "print(f\"\\nCreated from long-format DataFrame:\")\n",
    "print(f\"  Records: {log_long.num_records}\")\n",
    "print(f\"  Features: {log_long.num_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Temporal Window Analysis\n",
    "\n",
    "Create behavior log with 12 observations (e.g., 12 months) and analyze by quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T20:29:04.287873Z",
     "iopub.status.busy": "2026-01-09T20:29:04.287789Z",
     "iopub.status.idle": "2026-01-09T20:29:04.294359Z",
     "shell.execute_reply": "2026-01-09T20:29:04.293037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original log: 12 observations\n",
      "Split into 4 windows of 3 observations each\n",
      "\n",
      "  Window 1 (annual_user_window_0): integrity = 1.000\n",
      "  Window 2 (annual_user_window_1): integrity = 1.000\n",
      "  Window 3 (annual_user_window_2): integrity = 1.000\n",
      "  Window 4 (annual_user_window_3): integrity = 1.000\n",
      "\n",
      "Integrity trend: [1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "prices_12 = np.abs(np.random.randn(12, 3)) + 1.0\n",
    "quantities_12 = np.abs(np.random.randn(12, 3))\n",
    "\n",
    "log_12 = BehaviorLog(\n",
    "    cost_vectors=prices_12,\n",
    "    action_vectors=quantities_12,\n",
    "    user_id=\"annual_user\"\n",
    ")\n",
    "\n",
    "# Split into quarterly windows\n",
    "windows = log_12.split_by_window(window_size=3)\n",
    "\n",
    "print(f\"Original log: {log_12.num_records} observations\")\n",
    "print(f\"Split into {len(windows)} windows of 3 observations each\")\n",
    "print()\n",
    "\n",
    "for i, window_log in enumerate(windows):\n",
    "    integrity = compute_integrity_score(window_log).efficiency_index\n",
    "    print(f\"  Window {i+1} ({window_log.user_id}): integrity = {integrity:.3f}\")\n",
    "\n",
    "# Detect structural breaks (sudden changes in consistency)\n",
    "integrity_scores = [compute_integrity_score(w).efficiency_index for w in windows]\n",
    "print(f\"\\nIntegrity trend: {integrity_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7: Minimal Outlier Fraction (Houtman-Maks Index)\n",
    "\n",
    "What fraction of observations must be removed to achieve consistency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-09T20:29:04.296688Z",
     "iopub.status.busy": "2026-01-09T20:29:04.296567Z",
     "iopub.status.idle": "2026-01-09T20:29:04.301087Z",
     "shell.execute_reply": "2026-01-09T20:29:04.300409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is originally GARP consistent: True\n",
      "Outlier fraction: 0.000\n",
      "  (fraction of observations that need to be REMOVED)\n",
      "Removed observation indices: []\n",
      "Remaining observations: 1.000\n",
      "  (fraction of observations that ARE consistent)\n",
      "\n",
      "Comparison:\n",
      "  Afriat Efficiency Index: 1.000 (budget efficiency)\n",
      "  Houtman-Maks removal fraction: 0.000 (observation count)\n"
     ]
    }
   ],
   "source": [
    "# Create data with some violations (at equal prices, preferences flip)\n",
    "prices_hm = np.array([\n",
    "    [1.0, 1.0],\n",
    "    [1.0, 1.0],\n",
    "    [1.0, 1.0],\n",
    "    [1.0, 1.0],\n",
    "])\n",
    "quantities_hm = np.array([\n",
    "    [4.0, 1.0],  # Prefers A\n",
    "    [1.0, 4.0],  # Prefers B (violation!)\n",
    "    [3.0, 2.0],  # Prefers A\n",
    "    [2.0, 3.0],  # Prefers B (violation!)\n",
    "])\n",
    "\n",
    "log_hm = BehaviorLog(cost_vectors=prices_hm, action_vectors=quantities_hm)\n",
    "\n",
    "outlier_fraction, removed_indices = compute_minimal_outlier_fraction(log_hm)\n",
    "\n",
    "is_originally_consistent = validate_consistency(log_hm).is_consistent\n",
    "print(f\"Is originally GARP consistent: {is_originally_consistent}\")\n",
    "print(f\"Outlier fraction: {outlier_fraction:.3f}\")\n",
    "print(f\"  (fraction of observations that need to be REMOVED)\")\n",
    "print(f\"Removed observation indices: {removed_indices}\")\n",
    "print(f\"Remaining observations: {1 - outlier_fraction:.3f}\")\n",
    "print(f\"  (fraction of observations that ARE consistent)\")\n",
    "\n",
    "# Compare to Afriat Efficiency Index\n",
    "aei = compute_integrity_score(log_hm).efficiency_index\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Afriat Efficiency Index: {aei:.3f} (budget efficiency)\")\n",
    "print(f\"  Houtman-Maks removal fraction: {outlier_fraction:.3f} (observation count)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Applications\n",
    "\n",
    "```python\n",
    "# 1. SUPERAPP PRODUCT STRATEGY:\n",
    "result = test_feature_independence(user_log, rides_goods, food_goods)\n",
    "if result.is_separable:\n",
    "    print(\"Can price Rides and Food independently\")\n",
    "else:\n",
    "    print(\"Need unified pricing strategy - products are substitutes\")\n",
    "\n",
    "# 2. DETECT CANNIBALIZATION:\n",
    "impact = compute_cross_impact(user_log, new_product, existing_product)\n",
    "if impact['a_to_b'] > 0.3:\n",
    "    print(\"New product is cannibalizing existing product!\")\n",
    "\n",
    "# 3. STRUCTURAL BREAK DETECTION:\n",
    "windows = user_log.split_by_window(window_size=10)\n",
    "scores = [compute_integrity_score(w).efficiency_index for w in windows]\n",
    "for i in range(1, len(scores)):\n",
    "    if abs(scores[i] - scores[i-1]) > 0.2:\n",
    "        print(f\"Structural break at window {i}\")\n",
    "\n",
    "# 4. DATA PIPELINE INTEGRATION:\n",
    "# Load from database\n",
    "df = pd.read_sql(\"SELECT * FROM transactions\", conn)\n",
    "log = BehaviorLog.from_long_format(df, ...)\n",
    "\n",
    "# 5. CATEGORY MANAGEMENT:\n",
    "groups = discover_independent_groups(store_data, max_groups=5)\n",
    "for group in groups:\n",
    "    print(f\"Category {group}: can optimize independently\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
